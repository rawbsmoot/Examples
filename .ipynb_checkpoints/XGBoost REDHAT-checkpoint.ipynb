{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from IPython.display import Image\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import patsy\n",
    "from sklearn import neighbors, metrics, svm\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from operator import itemgetter\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7a68dfa1905d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_plotting_function(rate1, rate2, rate1_name, rate2_name, curve_name):\n",
    "    AUC = auc(rate1, rate2)\n",
    "    # Plot of a ROC curve \n",
    "    plt.figure(figsize=[11,9])\n",
    "    plt.plot(rate1, rate2, label=curve_name + ' (area = %0.2f)' % AUC, linewidth=4)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(rate1_name, fontsize = 18)\n",
    "    plt.ylabel(rate2_name, fontsize = 18)\n",
    "    plt.title(curve_name + ' Good Customer', fontsize=18)\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()\n",
    "def plot_roc(y_test, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    auc_plotting_function(fpr, tpr, 'False Positive Rate', 'True Positive Rate', 'ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act = pd.read_csv('/Users/smoot/Downloads/act_train.csv', parse_dates=['date'])\n",
    "ppl = pd.read_csv('/Users/smoot/Downloads/people.csv', parse_dates=['date'])\n",
    "# act_t = pd.read_csv(\"../../../Downloads/act_test.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(1, 11):\n",
    "#     act['char_' + str(i)].fillna(value = 'type 0', inplace = True)\n",
    "# for i in range(1, 11):\n",
    "#     act_t['char_' + str(i)].fillna(value = 'type 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act['char_1'].fillna(value = 'type 2', inplace = True)\n",
    "act['char_2'].fillna(value = 'type 2', inplace = True)\n",
    "act['char_3'].fillna(value = 'type 1', inplace = True)\n",
    "act['char_4'].fillna(value = 'type 3', inplace = True)\n",
    "act['char_5'].fillna(value = 'type 6', inplace = True)\n",
    "act['char_6'].fillna(value = 'type 2', inplace = True)\n",
    "act['char_7'].fillna(value = 'type 1', inplace = True)\n",
    "act['char_8'].fillna(value = 'type 4', inplace = True)\n",
    "act['char_9'].fillna(value = 'type 8', inplace = True)\n",
    "act['char_10'].fillna(value = 'type 1', inplace = True)\n",
    "# act_t['char_1'].fillna(value = 'type 2', inplace = True)\n",
    "# act_t['char_2'].fillna(value = 'type 2', inplace = True)\n",
    "# act_t['char_3'].fillna(value = 'type 1', inplace = True)\n",
    "# act_t['char_4'].fillna(value = 'type 3', inplace = True)\n",
    "# act_t['char_5'].fillna(value = 'type 6', inplace = True)\n",
    "# act_t['char_6'].fillna(value = 'type 2', inplace = True)\n",
    "# act_t['char_7'].fillna(value = 'type 1', inplace = True)\n",
    "# act_t['char_8'].fillna(value = 'type 4', inplace = True)\n",
    "# act_t['char_9'].fillna(value = 'type 8', inplace = True)\n",
    "# act_t['char_10'].fillna(value = 'type 1', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    ppl['char_' + str(i)] = ppl['char_' + str(i)].str.lstrip('type ').astype(np.int32) \n",
    "for i in range(10, 38):\n",
    "    ppl['char_' + str(i)] = ppl['char_' + str(i)].astype(np.int32)\n",
    "    \n",
    "for i in range(10, 11):\n",
    "    act['char_' + str(i)] = act['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n",
    "# for i in range(10, 11):\n",
    "#     act_t['char_' + str(i)] = act_t['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n",
    "\n",
    "for table in [act, ppl]:\n",
    "    table['year'] = table['date'].dt.year\n",
    "    table['month'] = table['date'].dt.month\n",
    "    table['day'] = table['date'].dt.day\n",
    "    \n",
    "del ppl['date']\n",
    "del act['date']\n",
    "y = act['outcome']\n",
    "del act['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# act.drop(act.ix[:, 4:13], inplace = True, axis = 1)\n",
    "# act_t.drop(act_t.ix[:, 4:13], inplace = True, axis = 1)\n",
    "# act.head()\n",
    "# act_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.merge(act, ppl, how='left', on='people_id')\n",
    "# df_t = pd.merge(act_t, ppl, how='left', on='people_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del act['year']\n",
    "# del act_t['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['people_id'] = df['people_id'].str.lstrip('ppl_ ')\n",
    "df['peoples_id'] = pd.to_numeric(df['people_id']) \n",
    "df['activity_category'] = df['activity_category'].str.lstrip('type ').astype(int, inplace = True)\n",
    "df['group_1'] = df['group_1'].str.lstrip('group ').astype(np.int32)\n",
    "del df['people_id']\n",
    "# del df['group_1']\n",
    "\n",
    "# df_t['people_id'] = df_t['people_id'].str.lstrip('ppl_ ')\n",
    "# df_t['peoples_id'] = pd.to_numeric(df_t['people_id']) \n",
    "# df_t['activity_category'] = df_t['activity_category'].str.lstrip('type ').astype(int, inplace = True)\n",
    "# df_t['group_1'] = df_t['group_1'].str.lstrip('group ').astype(np.int32)\n",
    "# del df_t['people_id']\n",
    "# del df_t['group_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del df['group_1']\n",
    "# del df_t['group_1']\n",
    "# del df['peoples_id']\n",
    "# del df_t['peoples_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df.ix[:, 1:])\n",
    "# X_t = pd.DataFrame(df_t.ix[:, 1:])\n",
    "X = pd.get_dummies(X)\n",
    "# X_t = pd.get_dummies(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.drop(X.ix[:, 133:138], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197291, 57)\n",
      "(2197291, 206)\n"
     ]
    }
   ],
   "source": [
    "# X.drop(X.ix[:, 156:162], inplace = True, axis = 1)\n",
    "# for i in np.ravel(X.columns), np.ravel(X_t.columns):\n",
    "#     if i == np.ravel(X.columns) & np.ravel(X_t.columns):\n",
    "#         print i\n",
    "# X_t = X_t.reindex_like(X)\n",
    "# print np.ravel(X_t.columns)\n",
    "print df.ix[:, 1:].shape\n",
    "# print df_t.ix[:, 1:].shape\n",
    "# print X_t.shape\n",
    "print X.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for table in [act, act_t]:\n",
    "#     table['year'] = table['date'].dt.year\n",
    "#     table['month'] = table['date'].dt.month\n",
    "#     table['day'] = table['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X['f_1'] = X.ix[:,3:4]\n",
    "# X['f_2'] = X.ix[:,4:5]\n",
    "# X['f_3'] = X.ix[:,8:9]\n",
    "# X['f_4'] = X.ix[:,9:10]\n",
    "# X['f_5'] = X.ix[:,40:41]\n",
    "# X['f_6'] = X.ix[:,41:42]\n",
    "\n",
    "# X_t['f_1'] = X_t.ix[:,3:4]\n",
    "# X_t['f_2'] = X_t.ix[:,4:5]\n",
    "# X_t['f_3'] = X_t.ix[:,8:9]\n",
    "# X_t['f_4'] = X_t.ix[:,9:10]\n",
    "# X_t['f_5'] = X_t.ix[:,40:41]\n",
    "# X_t['f_6'] = X_t.ix[:,41:42]\n",
    "\n",
    "# X = X.ix[:, 200:]\n",
    "# X_t = X_t.ix[:, 200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X['char38'] = X['char_38']\n",
    "# del X['char_38']\n",
    "# X_t['char38'] = X_t['char_38']\n",
    "# del X_t['char_38']\n",
    "\n",
    "# sc = MinMaxScaler()\n",
    "# X['char_38'] = sc.fit_transform(X['char38'])\n",
    "# X_t['char_38'] = sc.fit_transform(X_t['char38'])\n",
    "# X_t.drop(X_t.ix[:, 1:10], inplace = True, axis = 1)\n",
    "# X_t = mnsc.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "cols_t = list(df_t.columns)\n",
    "del cols[0]\n",
    "del cols_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99067489092641248"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_features = 'sqrt', n_estimators = 15, criterion = 'entropy', n_jobs = -1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = etc.predict_proba(X_t)\n",
    "pp = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = act_t['activity_id']\n",
    "\n",
    "submission = pd.DataFrame({'activity_id' : ids, 'outcome': pp})\n",
    "submission.to_csv('submission9.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnf = RandomForestClassifier(max_features = 'sqrt', criterion = 'entropy',  n_estimators = 50, n_jobs = -1)\n",
    "rnf.fit(X_train, y_train)\n",
    "rnf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99109361489100256"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(max_features = 'sqrt', n_estimators = 15, n_jobs = -1)\n",
    "etc.fit(X_train, y_train)\n",
    "etc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbs = DBSCAN(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = etc.feature_importances_\n",
    "std = np.std([etc.feature_importances_ for tree in etc.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color = \"r\", yerr = std[indices], align = \"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    {'n_estimators': [15, 50],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True],\n",
    "    'min_samples_split': [2, 3]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "# gs = GridSearchCV(rif, param_grid = params, n_jobs = -1)\n",
    "# gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = rf.predict_proba(X_t)\n",
    "ypred = rf.predict(X_t)\n",
    "pp = proba[:,1]\n",
    "# score = roc_auc_score(y_test, pp)\n",
    "# print(\"Area under ROC {0}\".format(score))\n",
    "# plot_roc(y_test, pp)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, n_estimators = 50, n_jobs = -1)\n",
    "rf_enc = OneHotEncoder()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_enc.fit(rf.apply(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_pred_rf_lm = rf.predict_proba(rf_enc.transform(rf.apply(X_test)))[:, 1]\n",
    "y_pred = rf.predict_proba(X_test)\n",
    "score = rf.score(X_test, y_test)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# proba = clf.predict_proba(X_test)\n",
    "# ypred = clf.predict(X_test)\n",
    "pp = y_pred[:,1]\n",
    "score = roc_auc_score(y_test, pp)\n",
    "print(\"Area under ROC {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size = 0.16, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logreg_parameters = {\n",
    "#     'penalty' : ['l2'],\n",
    "#     'C' : np.array([1, 0.1, 0.01, 0.001]),\n",
    "#     'solver' : ['liblinear']}\n",
    "# l_grid = GridSearchCV(lr, param_grid = logreg_parameters, n_jobs = -1)\n",
    "# l_grid.fit(X_train, y_train)\n",
    "# lreg_pred = log_grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs = -1)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pp = lr.predict_proba(X_test)\n",
    "y_pred = lr.predict(X_test)\n",
    "model_coefs = zip(cols, np.transpose(lr.coef_))\n",
    "\n",
    "lreg_pp_score = lr.decision_function(X_test)\n",
    "plot_roc(y_test, lreg_pp_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y, n_folds = 3)\n",
    "classifier = svm.SVC(kernel = 'linear',\n",
    "                     random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs = -1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba = clf.predict_proba(X_test)\n",
    "ypred = clf.predict(X_test)\n",
    "pp = proba[:,1]\n",
    "score = roc_auc_score(y_test, pp)\n",
    "print(\"Area under ROC {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(y_test, pp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 100, n_jobs = -1)\n",
    "etc.fit(X_train, y_train)\n",
    "etc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob = etc.predict_proba(X_test)\n",
    "ya_pred = etc.predict(X_test)\n",
    "preds_e = prob[:,1]\n",
    "score = roc_auc_score(y_test, preds_e)\n",
    "print(\"Area under ROC {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(y_test, preds_e)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_features = 'auto'),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         n_estimators=50)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pro = ada.predict_proba(X_test)\n",
    "yapred = ada.predict(X_test)\n",
    "preds_a = pro[:,1]\n",
    "score = roc_auc_score(y_test, preds_a)\n",
    "print(\"Area under ROC {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pro = etc.predict_proba(X_t)\n",
    "preds_a = pro[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = act_t['activity_id']\n",
    "\n",
    "submission = pd.DataFrame({'activity_id' : ids, 'outcome': pp})\n",
    "submission.to_csv('submission7.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(len(df_t.activity_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sum_wpos = sum( weight[i] for i in range(len(label)) if label[i] == 1.0  )\n",
    "\n",
    "# weight = df.ix[:, 1:] * float(len(df_t)) / len(y)\n",
    "# stc = StandardScaler()\n",
    "# X = stc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_count = 550000\n",
    "# weight = df.ix[:,1:] * float(test_count) / len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sum_wpos = []\n",
    "# if label[i] == 1:\n",
    "#     sum( weight[i] for i in range(test_count)).append(sum_wpos)\n",
    "# sum_wneg = []\n",
    "# if label[i] != 1:\n",
    "#     sum( weight[i] for i in range(test_count)).append(sum_wneg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sum_wpos = sum(weight[i] for i in range(len(y)) if y[i] == 1.0)\n",
    "# sum_wneg = sum(weight[i] for i in range(len(y)) if y[i] == 0.0)\n",
    "# print ('weight statistics: wpos=%g, wneg=%g, ratio=%g' % ( sum_wpos, sum_wneg, sum_wneg/sum_wpos ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, xgmat):\n",
    "    labels = xgmat.get_label()\n",
    "    assert len(preds) == len(labels)\n",
    "    labels = labels.tolist()\n",
    "    preds = preds.tolist()\n",
    "    terms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0,preds[i]) + 1)) ** 2.0 for i,pred in enumerate(labels)]\n",
    "    return 'error', (sum(terms_to_sum) * (1.0/len(preds))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df_t.activity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weight = df.ix[:,1:] * float(len(df_t.activity_id)) / len(y)\n",
    "\n",
    "# sum_wpos = sum( weight[i] for i in range(len(y)) if y[i] == 1.0  )\n",
    "# sum_wneg = sum( weight[i] for i in range(len(y)) if y[i] == 0.0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = df_t['activity_id']\n",
    "test = df_t.drop(['activity_id'],axis = 1)\n",
    "test_preds = np.zeros(df_t.shape[0])\n",
    "w = np.random.rand(5, 1)\n",
    "params = {}\n",
    "params['objective'] = \"binary:logitraw\"\n",
    "params['eta'] = 0.025\n",
    "params['max_depth'] = 6\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.8\n",
    "params['eval_metric'] = 'auc'\n",
    "params['alpha'] = 0.2\n",
    "params['gamma'] = 0.1\n",
    "params['booster'] = \"gbtree\"\n",
    "start_time = time.time()\n",
    "# params['scale_pos_weight'] = sum_wneg/sum_wpos\n",
    "\n",
    "param = {}\n",
    "param['objective'] = 'binary:logitraw'\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.6\n",
    "param['colsample_bytree'] = 0.6\n",
    "\n",
    "\n",
    "# 'ams@0.15'\n",
    "param['silent'] = 1\n",
    "# param['lambda'] = 0.9\n",
    "# scale weight of positive examples\n",
    "# param['scale_pos_weight'] = sum_wneg/sum_wpos\n",
    "\n",
    "\n",
    "plst = list(params.items())+[('eval_metric', 'ams@0.15')]\n",
    "\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size = 0.2, random_state = 3)\n",
    "xgmat = xgb.DMatrix(X_train, weight = w, label = y_train)\n",
    "xgmat_test = xgb.DMatrix(X_test)\n",
    "\n",
    "watchlist = [ (xgmat,'train') ]\n",
    "num_rounds = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('loading data end, start to boost trees')\n",
    "bst = xgb.train( param, xgmat, num_rounds, watchlist, feval = evalerror, early_stopping_rounds= 20, verbose_eval = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = bst.predict(xgmat_test, ntree_limit = bst.best_iteration)\n",
    "fold_preds = np.around(bst.predict(xgmat_test, ntree_limit = bst.best_iteration), decimals = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2197291 entries, 0 to 2197290\n",
      "Columns: 201 entries, activity_category to char_9_x_type 9\n",
      "dtypes: float64(154), int32(39), int64(8)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = X\n",
    "label = y\n",
    "dtrain = xgb.DMatrix(data, label = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ml_metrics import rmsle\n",
    "\n",
    "params = {\n",
    "params['objective'] = \"reg:linear\"\n",
    "params['eta'] = 0.025\n",
    "params['max_depth'] = 5\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['silent'] = True\n",
    "}\n",
    "\n",
    "print ('')\n",
    "\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test)\n",
    "\n",
    "watchlist = [(xg_train, 'train')]\n",
    "num_rounds = 100\n",
    "\n",
    "xgclassifier = xgb.train(params, xg_train, num_rounds, watchlist, early_stopping_rounds= 20, verbose_eval = 10)\n",
    "preds = xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration)\n",
    "\n",
    "print ('RMSLE Score:', rmsle(y_test, preds))\n",
    "\n",
    "fxg_test = xgb.DMatrix(test)\n",
    "fold_preds = np.around(xgclassifier.predict(fxg_test, ntree_limit=xgclassifier.best_iteration), decimals = 1)\n",
    "test_preds += fold_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  There are four people who makeup nearly half of the activites.  I'm not sure how to deal with that but this cell \n",
    "#  identifies the people and their index in the ppl dataframe.\n",
    "\n",
    "# r_list = ['ppl_294918', 'ppl_370270', 'ppl_105739', 'ppl_54699']\n",
    "# for i, l in enumerate(ppl['people_id'] == 'ppl_54699'):\n",
    "#     if l == True:\n",
    "#         print i\n",
    "# for i in r_list:\n",
    "#     ppl.drop(ppl[ppl['people_id']==i],axis=0)\n",
    "# [ppl.drop([i], axis = 0, inplace = True) for i in enumerate(ppl.people_id) if i == r_list]\n",
    "# ppl.drop([102743], inplace = True)\n",
    "# ppl.drop([142792], inplace = True)\n",
    "# ppl.drop([3038], inplace = True)\n",
    "# ppl.drop([165422], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "test_size = 550000\n",
    "\n",
    "# path to where the data lies\n",
    "dpath = 'data'\n",
    "\n",
    "# load in training data, directly use numpy\n",
    "dtrain = np.loadtxt( dpath+'/training.csv', delimiter=',', skiprows=1, converters={32: lambda x:int(x=='s'.encode('utf-8')) } )\n",
    "print ('finish loading from csv ')\n",
    "\n",
    "label  = dtrain[:,32]\n",
    "data   = dtrain[:,1:31]\n",
    "# rescale weight to make it same as test set\n",
    "weight = dtrain[:,31] * float(test_size) / len(label)\n",
    "\n",
    "sum_wpos = sum( weight[i] for i in range(len(label)) if label[i] == 1.0  )\n",
    "sum_wneg = sum( weight[i] for i in range(len(label)) if label[i] == 0.0  )\n",
    "\n",
    "# print weight statistics\n",
    "print ('weight statistics: wpos=%g, wneg=%g, ratio=%g' % ( sum_wpos, sum_wneg, sum_wneg/sum_wpos ))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
